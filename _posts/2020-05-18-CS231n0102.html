---
layout: post
title: "CS231n_0102"
subtitle: "lecture 1,2 review"
date: 2020-05-17 23:45:13 -0400
background: '/img/posts/01.jpg'
---

<p> As the animal get vision, it boost the increase of population.</p>
<p> For intelligent animals, sight is very important. Cause it gives a huge impact on survival.</p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82214007-09daf780-9950-11ea-8055-fcf74c970100.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> Primary visual cortex of a cat brain research: Inspire computer vision</p>
<p> Computer vision studies how animals perceive objects visually.</p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224015-575e6100-995e-11ea-8718-a90dd3e1f1b7.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> How computers accept visual world:</p>
<p> Primal scatch(edge,curve)-->Feature extraction --> Make into 3D based on collected Features </p>
<p> ”Make a complex shape simple”</p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224017-57f6f780-995e-11ea-91fb-7552f391c1c2.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> If object recognition is too difficult, split it up into meaningful area --> “Object Segmentation”</p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224021-57f6f780-995e-11ea-82b5-856a43c9235c.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> SIFT feature: Match feature point </p>
<p> * feature point :Some features that tend to remain diagnostic and invariant to changes </p>
<p>  ”Identify critical feature and match them to a similar point” </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224025-59282480-995e-11ea-93cf-21c2cfa2c9aa.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> Spatial Pyramid Matching: </p>
<p> Each image has a hint of what kind of scenery it is --> Gather features and put it in feature descriptor --> Run support vector machine algorithm</p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224028-59282480-995e-11ea-9652-fd292f8e8d00.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> As time goes by, more data is created and image quality is improved. And this suits the needs of studying the vision of the computer. </p>
<p> Since the 2000s, PASCAL visual Object challenge opened. </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224035-5a595180-995e-11ea-92de-72f61e38f034.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> Cause we can get huge dataset through Imagenet, make object recognition into another phase </p>
<p> You can see the error rate decreasing as time goes by. </p>
<p> In 2012, affected by the deep learning model, error rate is greatly reduced.   “Why Deep Learning became popular” </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224037-5b8a7e80-995e-11ea-935d-e05817bd3f7d.PNG" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> CNN's Progress: Getting deeper and deeper, It become an important tool for object recognition.  </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224039-5c231500-995e-11ea-8073-4abedb467328.PNG" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> Why Deep Learning become popular? </p>
<p> 1. GPU’s super parallelizable function </p>
<p> 2. Development of dataset: Pascal, Imagenet </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224043-5cbbab80-995e-11ea-8407-a61430e04f90.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p>  How do image classification works?  </p>
<p>  --> System receives some input image and assign it to particular category labels. </p>
<p> When we moved the camera, then every single pixel would become different. But, it's still representing the same cat. And our algorithms need to be robust to this. </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224044-5cbbab80-995e-11ea-8126-f5a30cb63671.PNG" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> < A problematic situation >  </p>
<p> 1.Illumination: There can be different lighting conditions.   </p>
<p> 2.Objects can be deform: Our algorithms should be robust to these different kinds of transforms.   </p>
<p> 3.Occlusion: When we only see part of a object.  </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224047-5d544200-995e-11ea-9a59-54ba85e3d5da.PNG" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> Once we get this dataset, we train this machine learning classifier. Finally, we'll use this training model and classify it on new images.  </p>
<p> Now we have two function in this process. </p>
<p> 1. Train: Input images and labels and then output a model. The model will memorize all of the training data.  </p>
<p> 2. Predict: Which will input the model and than make predictions for new images.  </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224049-5decd880-995e-11ea-8460-0bf63a527f0f.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> CIFAR-10 dataset gives 10 different classes And it provides 50,000 training images, and also 10,000 additional testing images.  </p>
<p> Here's an example of classifier of these test images on CIFAR-10 on the right. You can see the most similar training images sorted to each of these test image.  </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224051-5decd880-995e-11ea-9a53-df206b4f86a3.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> How to figure out the difference between two images: --> Manhattan distance.  </p>
<p> First, subtract the pixel value of the training image from the pixel value of the test image and take the absolute value.  </p>
<p> And then, sum all these differences.   </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223962-4e6d8f80-995e-11ea-873b-a8db3b274b59.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> An code of an nearest neighbor classifier.</p>
<p> In the train method, it just memorize the training data.  </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223967-50375300-995e-11ea-899a-f591e80ccaef.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> And in the predict method, it will go on a comparing using L1 distance function.   </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223969-50cfe980-995e-11ea-8b60-920478dcee4f.png" alt="Demo Image">

<br>
<br>
<br>
<p> How fast the training and testing be?  </p>
<p> Training :constant --> We just have to memorize the data.  </p>
<p> Predict : N --> We will compare our test image to each of the N training examples in the dataset.    </p>
<p> What we really want is the testing time performance to be fast.   </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223972-50cfe980-995e-11ea-9ba1-6f964158191d.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> < k-nearest neighbors >   </p>
<p>  --> Generalization algorithm </p>
<p> K's role indicates how close the data will be to be combined.  </p>
<p> “The larger the k, the more effective it is to smoothe out the boundary.”  </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223974-51688000-995e-11ea-8ad8-92b9875b9630.PNG" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> <Euclidean distance>  </p>
<p> Where you take the square root of the sum of the squares and take this as your distance.  </p>
<p> If you were to rotate the coordinate frame that would change the L1 distance between the points. But L2 distance doesn't matter.  </p>
<p> If input features have some important meaning,L1 might be a more natural fit. But if you don't know what they actually mean, then maybe L2 is more natural.	  </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223980-52011680-995e-11ea-8213-1d8ce0ce21bb.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223984-53324380-995e-11ea-89f9-7aaeabc6c888.png" alt="Demo Image">
<p> * hyperparameter : a  parameter whose value is set before the learning process begins  </p>
<p></p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223989-53324380-995e-11ea-83c2-e9a54dc9e0e3.png" alt="Demo Image">
<p></p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223990-53cada00-995e-11ea-8658-50834c21e0dd.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p> Problem with the k-nearest neighbor classifier : The curse of dimensionality. K   </p>
<p> --> In high dimensions, the number of training examples have to densely cover the space .  </p>
<p> “Grows exponentially with the dimension”  </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82227276-8545a480-9962-11ea-8ae0-bffffc529262.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<p>  Deep Neural Networks are like Legos and this linear classifier is the basic building blocks of these giant networks. </p>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82223998-54637080-995e-11ea-8d03-c8a9f1e99819.png" alt="Demo Image">

<br>
<br>
<br>
<br>
<br>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82227279-85de3b00-9962-11ea-9bdb-9fcc1a88d0f6.png" alt="Demo Image">
<p> Parametric model has two different components.  </p>
<p> X:input data,  W: weights </p>
<p> It will spit out 10 numbers describing what corresponding to each of those 10classes in CIFAR-10.  </p>

<br>
<br>
<br>
<br>
<br>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224001-54fc0700-995e-11ea-9c2f-d77375b4ac79.png" alt="Demo Image">
<p> *bias: This could gives us data independent preferences for some classes over another.  </p>

<br>
<br>
<br>
<br>
<br>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224006-55949d80-995e-11ea-8ec1-c6d83b929795.png" alt="Demo Image">
<p> Interpreting a Linear Classifier  </p>
<p> Take the rows of that weight matrix and unravel them back into images   </p>
<p> --> Templates as images gives us what a linear classifier might actually be doing to try to understand the data. </p>

<br>
<br>
<br>
<br>
<br>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224010-562d3400-995e-11ea-86cd-928e2eda1658.png" alt="Demo Image">
<p> If we consider each of our images as a point in 2d, the linear classifier will draw a line. And it separates between one category and the rest of them. </p>

<br>
<br>
<br>
<br>
<br>
<img class="img-fluid" src="https://user-images.githubusercontent.com/44043931/82224011-56c5ca80-995e-11ea-9dd0-af316f26be6a.png" alt="Demo Image">
<p> A problems that linear classification have:  </p>
<p> We can draw a single linear line to separate blue and red.	 However, as you can see in the picture, in some cases is hard to separate.  </p>

